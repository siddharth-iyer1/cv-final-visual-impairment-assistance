{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_keypoints_and_descriptors(image):\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "    return keypoints, descriptors\n",
    "\n",
    "def match_features(desc1, desc2):\n",
    "    matcher = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "    matches = matcher.match(desc1, desc2)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "    return matches\n",
    "\n",
    "def draw_matches(img1, kp1, img2, kp2, matches):\n",
    "    return cv2.drawMatches(img1, kp1, img2, kp2, matches[:50], None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "def stereo_calibrate(kp1, kp2, matches, img1_shape):\n",
    "    # Convert keypoints to an array of points\n",
    "    points1 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "    points2 = np.zeros_like(points1)\n",
    "\n",
    "    for i, match in enumerate(matches):\n",
    "        points1[i, :] = kp1[match.queryIdx].pt\n",
    "        points2[i, :] = kp2[match.trainIdx].pt\n",
    "\n",
    "    # Camera calibration\n",
    "    focal_length = img1_shape[1]\n",
    "    center = (img1_shape[1]/2, img1_shape[0]/2)\n",
    "    camera_matrix = np.array([[focal_length, 0, center[0]],\n",
    "                            [0, focal_length, center[1]],\n",
    "                            [0, 0, 1]], dtype=np.float32)\n",
    "\n",
    "    # Assuming no lens distortion\n",
    "    dist_coeffs = np.zeros(4)\n",
    "\n",
    "    # Stereo calibration\n",
    "    ret, mtx1, dist1, mtx2, dist2, R, T, E, F = cv2.stereoCalibrate(\n",
    "        [points1, points2], camera_matrix, dist_coeffs, camera_matrix, dist_coeffs,\n",
    "        img1_shape[::-1], None, None, criteria=(cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 1e-5),\n",
    "        flags=cv2.CALIB_FIX_INTRINSIC)\n",
    "    \n",
    "    return mtx1, dist1, mtx2, dist2, R, T\n",
    "\n",
    "# Load images\n",
    "img1 = cv2.imread('path_to_left_image.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "img2 = cv2.imread('path_to_right_image.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Find keypoints and descriptors\n",
    "kp1, desc1 = find_keypoints_and_descriptors(img1)\n",
    "kp2, desc2 = find_keypoints_and_descriptors(img2)\n",
    "\n",
    "# Match features\n",
    "matches = match_features(desc1, desc2)\n",
    "\n",
    "# Optionally draw matches\n",
    "matched_img = draw_matches(img1, kp1, img2, kp2, matches)\n",
    "\n",
    "# Stereo calibration\n",
    "mtx1, dist1, mtx2, dist2, R, T = stereo_calibrate(kp1, kp2, matches, img1.shape)\n",
    "\n",
    "print(\"Intrinsic Matrix for Camera 1:\", mtx1)\n",
    "print(\"Intrinsic Matrix for Camera 2:\", mtx2)\n",
    "print(\"Rotation Matrix:\", R)\n",
    "print(\"Translation Vector:\", T)\n",
    "\n",
    "# Show matched image\n",
    "cv2.imshow('Matches', matched_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
